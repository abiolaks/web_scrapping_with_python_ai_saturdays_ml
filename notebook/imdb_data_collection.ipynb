{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f3461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0364984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page starting at movie 1...\n",
      "Scraping page starting at movie 51...\n",
      "Scraping page starting at movie 101...\n",
      "Scraping page starting at movie 151...\n",
      "Scraping page starting at movie 201...\n",
      "Scraping page starting at movie 251...\n",
      "Scraping page starting at movie 301...\n",
      "Scraping page starting at movie 351...\n",
      "Scraping page starting at movie 401...\n",
      "Scraping page starting at movie 451...\n",
      "Scraping page starting at movie 501...\n",
      "Scraping page starting at movie 551...\n",
      "Scraping page starting at movie 601...\n",
      "Scraping page starting at movie 651...\n",
      "Scraping page starting at movie 701...\n",
      "Scraping page starting at movie 751...\n",
      "Scraping page starting at movie 801...\n",
      "Scraping page starting at movie 851...\n",
      "Scraping page starting at movie 901...\n",
      "Scraping page starting at movie 951...\n",
      "Scraped 0 movies and saved to imdb_movies.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "BASE_URL = \"https://www.imdb.com/search/title/?title_type=feature&sort=num_votes,desc&start={}&ref_=adv_nxt\"\n",
    "\n",
    "movies_data = []\n",
    "\n",
    "def scrape_movies(pages=5):  # pages = number of 50-item pages to scrape\n",
    "    for page in range(1, pages * 50, 50):\n",
    "        print(f\"Scraping page starting at movie {page}...\")\n",
    "        url = BASE_URL.format(page)\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        movie_containers = soup.find_all(\"div\", class_=\"lister-item mode-advanced\")\n",
    "\n",
    "        for movie in movie_containers:\n",
    "            title = movie.h3.a.text if movie.h3.a else None\n",
    "            year = movie.h3.find(\"span\", class_=\"lister-item-year\").text if movie.h3.find(\"span\", class_=\"lister-item-year\") else None\n",
    "            genre = movie.find(\"span\", class_=\"genre\").text.strip() if movie.find(\"span\", class_=\"genre\") else None\n",
    "            rating = movie.find(\"div\", class_=\"inline-block ratings-imdb-rating\").strong.text if movie.find(\"div\", class_=\"inline-block ratings-imdb-rating\") and movie.find(\"div\", class_=\"inline-block ratings-imdb-rating\").strong else None\n",
    "            summary = movie.find_all(\"p\", class_=\"text-muted\")\n",
    "            description = summary[1].text.strip() if len(summary) > 1 else None\n",
    "\n",
    "            movies_data.append({\n",
    "                \"Title\": title,\n",
    "                \"Year\": year,\n",
    "                \"Genre\": genre,\n",
    "                \"Rating\": rating,\n",
    "                \"Description\": description\n",
    "            })\n",
    "\n",
    "        time.sleep(1)  # be polite and avoid overloading the server\n",
    "\n",
    "scrape_movies(pages=20)  # 20 pages â†’ 1,000 movies\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(movies_data)\n",
    "df.to_csv(\"../scraped_data/imdb_movies.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Scraped {len(movies_data)} movies and saved to imdb_movies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Top 250 list...\n",
      "Data saved to imdb_top250_enriched.csv\n"
     ]
    }
   ],
   "source": [
    "# enrichment script for IMDb Top 250 movies\n",
    "# adding more details like summary, director, runtime, and cast\n",
    "\n",
    "BASE_CHART_URL = \"https://www.imdb.com/chart/top/\"\n",
    "BASE_TITLE_URL = \"https://www.imdb.com\"\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def parse_movie_detail(url):\n",
    "    \"\"\"Fetch and parse details from a movie's detail page.\"\"\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "    # Extract summary\n",
    "    summary = soup.find(\"span\", {\"data-testid\": \"plot-l\"}).text.strip() \\\n",
    "        if soup.find(\"span\", {\"data-testid\": \"plot-l\"}) else None\n",
    "    \n",
    "    # Extract director(s)\n",
    "    director = soup.find(\"a\", {\"data-testid\": \"title-pc-principal-credit\"}).text.strip() \\\n",
    "        if soup.find(\"a\", {\"data-testid\": \"title-pc-principal-credit\"}) else None\n",
    "    \n",
    "    # Extract runtime\n",
    "    runtime = soup.find(\"li\", {\"data-testid\": \"title-techspec_runtime\"})\n",
    "    runtime = runtime.text.strip() if runtime else None\n",
    "    \n",
    "    # Extract cast (first 3)\n",
    "    cast_list = [a.text for a in soup.select(\"a[data-testid*='title-cast-item__actor']\")][:3]\n",
    "    cast = \", \".join(cast_list)\n",
    "    \n",
    "    return summary, director, runtime, cast\n",
    "\n",
    "def scrape_top_250():\n",
    "    print(\"Fetching Top 250 list...\")\n",
    "    resp = requests.get(BASE_CHART_URL, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "    rows = soup.select(\"tbody.lister-list tr\")\n",
    "    movies = []\n",
    "    \n",
    "    for row in rows:\n",
    "        title = row.find(\"td\", class_=\"titleColumn\").a.text\n",
    "        year = row.find(\"td\", class_=\"titleColumn\").span.text.strip(\"()\")\n",
    "        rating = row.find(\"td\", class_=\"ratingColumn imdbRating\").strong.text\n",
    "        \n",
    "        link = BASE_TITLE_URL + row.find(\"td\", class_=\"titleColumn\").a[\"href\"].split('?')[0]\n",
    "        summary, director, runtime, cast = parse_movie_detail(link)\n",
    "        print(f\"Scraped: {title} ({year})\")\n",
    "        \n",
    "        movies.append({\n",
    "            \"title\": title,\n",
    "            \"year\": year,\n",
    "            \"rating\": rating,\n",
    "            \"summary\": summary,\n",
    "            \"director\": director,\n",
    "            \"runtime\": runtime,\n",
    "            \"cast\": cast\n",
    "        })\n",
    "        time.sleep(1)  # polite delay\n",
    "    \n",
    "    return movies\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_top_250()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"../scraped_data/imdb_top250_enriched.csv\", index=False)\n",
    "    print(\"Data saved to imdb_top250_enriched.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b387a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
